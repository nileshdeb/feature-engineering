{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7166db1a",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc603e3",
   "metadata": {},
   "source": [
    "Creating, transforming, or selecting features (input variables) to improve the performance of machine learning models.\n",
    "\n",
    "\n",
    "üõ†Ô∏è Raw data ‚Üí Useful features ‚Üí Better model accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c0c355",
   "metadata": {},
   "source": [
    "### Key Tasks in Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd225ddc",
   "metadata": {},
   "source": [
    "1. üßπ Handling Missing Data\n",
    "2. ‚öñÔ∏è Handling Imbalanced Datasets\n",
    "3. üå± SMOTE (Synthetic Minority Over-sampling Technique)\n",
    "4. ‚ö†Ô∏è Handling Outliers\n",
    "5. üî§ Data Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4a274e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c104333",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('sales.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd1a2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408527cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9acae675",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sns.load_dataset(\"titanic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb8081e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d0f542",
   "metadata": {},
   "outputs": [],
   "source": [
    "## check missing values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6d050f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8ab64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21066ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#coloumn wise deletion\n",
    "df.dropna(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2f8ea3",
   "metadata": {},
   "source": [
    "## Imputation Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93331cc7",
   "metadata": {},
   "source": [
    "Imputation is the process of replacing missing (null/NaN) values in your dataset with substitute values, so you can use the data for analysis or machine learning without errors.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b38a1de",
   "metadata": {},
   "source": [
    "1.Mean value imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0bcb84f",
   "metadata": {},
   "source": [
    "Mean imputation is a method where missing values in a numerical column are replaced with the mean (average) of the non-missing values of that column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eddfe6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(df['age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5b7c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Age_mean']=df['age'].fillna(df['age'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d89bc98",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Age_mean','age']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f227cb7",
   "metadata": {},
   "source": [
    "^\n",
    "  Mean imputation works well when we have normally distributed data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c450fd8b",
   "metadata": {},
   "source": [
    "2.Median value imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb61d17",
   "metadata": {},
   "source": [
    "Median imputation replaces missing values in a numerical column with the median (middle value) of the non-missing entries.\n",
    "\n",
    "why it use?\n",
    "\n",
    "if we have outliers in the dataset\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49e73b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['age_median']=df['age'].fillna(df['age'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de043974",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['age_median','age']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed23151",
   "metadata": {},
   "source": [
    "3. Mode imputation technique"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536d7fe3",
   "metadata": {},
   "source": [
    "Mode Imputation is a data cleaning technique where missing values in a column are filled with the mode ‚Äî the value that appears most frequently in that column.\n",
    "\n",
    "why use--Mainly for categorical features (e.g., Gender, City, Department)\n",
    "\n",
    " Also used for discrete numerical data with repeating values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e149fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bd5d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"embarked\"].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2d8768",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['embarked'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99e5dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode_value=df[df['embarked'].notna()]['embarked'].mode()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3d1c6a",
   "metadata": {},
   "source": [
    "1. df['embarked'].notna()\n",
    "Returns a Boolean Series: True where 'embarked' is not null, and False where it is NaN.\n",
    "\n",
    "2. df[df['embarked'].notna()]\n",
    "Filters the DataFrame to include only rows where 'embarked' is not missing.\n",
    "\n",
    "3. ['embarked']\n",
    "Selects the 'embarked' column from the filtered DataFrame.\n",
    "\n",
    "4. .mode()\n",
    "Calculates the mode (most frequent value) of the 'embarked' column.\n",
    "\n",
    "This returns a Series with the most frequent value(s).\n",
    "\n",
    "5. [0]\n",
    "Gets the first value of the mode series. Even though mode can return multiple values, here we pick just one (the most common one)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e6879f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['embarked_mode']=df['embarked'].fillna(mode_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f88a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['embarked_mode','embarked']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b84f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['embarked_mode'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cdc4cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['embarked'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f69a4b",
   "metadata": {},
   "source": [
    "## Handling Imbalance Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1942da94",
   "metadata": {},
   "source": [
    "1. up sampling\n",
    "2. Down sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08d46a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Set the random seed for reproducibility\n",
    "np.random.seed(123)\n",
    "\n",
    "# Create a dataframe with two classes\n",
    "n_samples = 1000\n",
    "class_0_ratio = 0.9\n",
    "n_class_0 = int(n_samples * class_0_ratio)\n",
    "n_class_1 = n_samples - n_class_0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff69056",
   "metadata": {},
   "source": [
    "np.random.seed(123): Ensures the random numbers generated will be the same every time you run the code ‚Äî great for reproducibility in experiments or models.\n",
    "\n",
    "You are going to create 1,000 total samples.\n",
    "class_0_ratio = 0.9 means 90% of the samples will belong to Class 0.\n",
    "\n",
    "n_class_0 = int(1000 * 0.9) ‚Üí n_class_0 = 900\n",
    "So, you‚Äôll have 900 samples for Class 0.\n",
    "\n",
    "n_class_1 = 1000 - 900 ‚Üí n_class_1 = 100\n",
    "The remaining 100 samples will be for Class 1.\n",
    "\n",
    "Class 0 ‚Üí 900 samples\n",
    "Class 1 ‚Üí 100 samples\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3e3273",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_class_0,n_class_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d537cb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "## CREATE MY DATAFRAME WITH IMBALANCED DATASET\n",
    "class_0 = pd.DataFrame({\n",
    "    'feature_1': np.random.normal(loc=0, scale=1, size=n_class_0),\n",
    "    'feature_2': np.random.normal(loc=0, scale=1, size=n_class_0),\n",
    "    'target': [0] * n_class_0\n",
    "})\n",
    "\n",
    "class_1 = pd.DataFrame({\n",
    "    'feature_1': np.random.normal(loc=2, scale=1, size=n_class_1),\n",
    "    'feature_2': np.random.normal(loc=2, scale=1, size=n_class_1),\n",
    "    'target': [1] * n_class_1\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084d6347",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.concat([class_0,class_1]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161a87b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9266fd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64bce12a",
   "metadata": {},
   "source": [
    "upsampling-- Increasing the number of samples in the minority class by duplicating or generating new synthetic data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0d5933",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_minority=df[df['target']==1]\n",
    "df_majority=df[df['target']==0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca753b35",
   "metadata": {},
   "source": [
    "df_minority: All rows where target == 1 (minority class)\n",
    "\n",
    "df_majority: All rows where target == 0 (majority class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eea34f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "df_minority_upsampled=resample(df_minority,replace=True,\n",
    "         n_samples=len(df_majority),\n",
    "         random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d6440e",
   "metadata": {},
   "source": [
    "replace=True: Allows the same row to be picked more than once (i.e., with replacement).\n",
    "\n",
    "n_samples=len(df_majority): You're making the number of samples in the minority class equal to the majority class.\n",
    "\n",
    "This is upsampling the minority class to balance the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e72ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_minority_upsampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1993fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_upsampled=pd.concat([df_majority,df_minority_upsampled])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f01f84e",
   "metadata": {},
   "source": [
    " now i have a balanced dataset: both classes have equal number of samples.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cf60d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_upsampled['target'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08345528",
   "metadata": {},
   "source": [
    "## Down sampling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe8de41",
   "metadata": {},
   "source": [
    "Reducing the number of samples in the majority class to match the minority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3560096e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_minority=df[df['target']==1]\n",
    "df_majority=df[df['target']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afae8a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "df_majority_downsampled=resample(df_majority,replace=False,\n",
    "         n_samples=len(df_minority),\n",
    "         random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9ed7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_majority_downsampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c957595",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_downsampled=pd.concat([df_minority,df_majority_downsampled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8599879c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_downsampled.target.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f7a779",
   "metadata": {},
   "source": [
    "## SMOTE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08af9985",
   "metadata": {},
   "source": [
    "SMOTE doesn‚Äôt just copy ‚Äî it creates new fake data points for Class 1 using math.\n",
    "\n",
    "Here‚Äôs how:\n",
    "\n",
    "Pick a Class 1 data point.\n",
    "\n",
    "Look at its nearest neighbors (other similar Class 1 points).\n",
    "\n",
    "Draw a line between them.\n",
    "\n",
    "Add a new point somewhere on that line.\n",
    "\n",
    "üß¨ This creates new, slightly different data, not duplicates.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4d60a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa8fd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y=make_classification(n_samples=1000,n_redundant=0,n_features=2,n_clusters_per_class=1,\n",
    "                    weights=[0.90],random_state=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25356942",
   "metadata": {},
   "source": [
    "n_samples=1000: Create 1000 total rows (data points).\n",
    "\n",
    "n_features=2: We‚Äôll have only 2 input features (f1 and f2).\n",
    "\n",
    "n_redundant=0: No extra unnecessary (redundant) features.\n",
    "\n",
    "n_clusters_per_class=1: One cluster per class for simplicity.\n",
    "\n",
    "weights=[0.90]: 90% of samples are class 0, and 10% are class 1 ‚Äî this creates imbalance.\n",
    "\n",
    "random_state=12: Ensures you get the same result every time (reproducibility).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e78752f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df1=pd.DataFrame(x,columns=['f1','f2'])\n",
    "df2=pd.DataFrame(y,columns=['target'])\n",
    "final_df=pd.concat([df1,df2],axis=1)\n",
    "final_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119f07a0",
   "metadata": {},
   "source": [
    "We're converting the NumPy arrays X and y into DataFrames for easy handling.\n",
    "\n",
    "Then, we combine features and target columns into a single DataFrame: final_df.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ba0949",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d4abea",
   "metadata": {},
   "source": [
    "A print of how many samples belong to class 0 vs class 1 ‚Äî you'll see class 0 has many more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b917ce2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(final_df['f1'],final_df['f2'],c=final_df['target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c6fb2e",
   "metadata": {},
   "source": [
    "A 2D scatter plot where points are colored based on the class (target) ‚Äî class imbalance is visually clear.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d8d6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdce9f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "## transform the dataset\n",
    "oversample=SMOTE()\n",
    "X,y=oversample.fit_resample(final_df[['f1','f2']],final_df['target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6a6191",
   "metadata": {},
   "source": [
    "SMOTE Magic:\n",
    "SMOTE = Synthetic Minority Over-sampling Technique.\n",
    "\n",
    "It generates new (synthetic) data points for the minority class by interpolating between existing minority samples.\n",
    "\n",
    "Result: Classes become balanced ‚Äî the number of class 1 samples now equals class 0.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf79c277",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d0c00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5050d603",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y[y==0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ba73ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y[y==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301e8e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.DataFrame(X,columns=['f1','f2'])\n",
    "df2=pd.DataFrame(y,columns=['target'])\n",
    "oversample_df=pd.concat([df1,df2],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659b05e4",
   "metadata": {},
   "source": [
    "Same as before ‚Äî convert the resampled arrays into a clean DataFrame to use in ML or visualization.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028a7eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(oversample_df['f1'],oversample_df['f2'],c=oversample_df['target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60036dae",
   "metadata": {},
   "source": [
    "Now the plot will show a balanced distribution ‚Äî visually you'll see more class 1 points\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857d01d5",
   "metadata": {},
   "source": [
    "## Handling outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba63682",
   "metadata": {},
   "source": [
    "### 5 number summary and box plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5bdddc",
   "metadata": {},
   "source": [
    "minimum, maximum, median , Q1, Q3 IQR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9c04ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57012ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_marks=[45,32,56,75,89,54,32,89,90,87,67,54,45,98,99,67,74]\n",
    "minimum,Q1,median,Q3,maximum=np.quantile(lst_marks,[0,0.25,0.50,0.75,1.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b19690f",
   "metadata": {},
   "outputs": [],
   "source": [
    "minimum,Q1,median,Q3,maximum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09310e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "IQR=Q3-Q1\n",
    "print(IQR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d920cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_fence=Q1-1.5*(IQR)\n",
    "higher_fence=Q3+1.5*(IQR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87af29ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_fence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc927d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "higher_fence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a577c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_marks=[45,32,56,75,89,54,32,89,90,87,67,54,45,98,99,67,74]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29025df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0147522c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(lst_marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e296e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_marks=[-100,-200,45,32,56,75,89,54,32,89,90,87,67,54,45,98,99,67,74,150,170,180]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79bb823",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(lst_marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62778a46",
   "metadata": {},
   "source": [
    "## Data encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80799ec7",
   "metadata": {},
   "source": [
    "It's a technique to convert categorical data into numbers. ML algorithms can't handle text, so we encode categories as numbers.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec16727",
   "metadata": {},
   "source": [
    "### Nominal/One hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95116e09",
   "metadata": {},
   "source": [
    "One Hot Encoding transforms categorical variables into binary vectors.\n",
    "Each unique category gets its own column, and we use 0 or 1 to indicate the presence of that category.\n",
    "\n",
    " Why Use It?\n",
    "Categorical data like [\"Red\", \"Green\", \"Blue\"] can't be directly used by ML models.\n",
    "\n",
    "One Hot Encoding avoids giving categories any implicit order (unlike label encoding).\n",
    "\n",
    "red green blue\n",
    "1\t 0\t   0\n",
    "0\t 1\t   0\n",
    "0\t 0\t   1\n",
    "1\t 0\t   0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910c7e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330e1407",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame({'color':['red','blue','green','green','red','blue']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8aae4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0812744e",
   "metadata": {},
   "source": [
    "create an instance of Onehotencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c89a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder=OneHotEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d746b4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## perform fit and transform\n",
    "encoded=encoder.fit_transform(df[['color']]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672b806b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "encoder_df=pd.DataFrame(encoded,columns=encoder.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629d58de",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5ecc3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "##for new data\n",
    "encoder.transform([['blue']]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce0dbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([df,encoder_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbc1032",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.load_dataset('tips')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "befc1a0e",
   "metadata": {},
   "source": [
    "### Label Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aec9afd",
   "metadata": {},
   "source": [
    "Label Encoding is the process of converting categorical text data (like 'Red', 'Green') into numerical labels (like 0, 1, 2).\n",
    "\n",
    "Each unique category is assigned an integer value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0e27ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b5026b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "lbl_encoder=LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1734da6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lbl_encoder.fit_transform(df[['color']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd34c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "lbl_encoder.transform([['red']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daab090b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lbl_encoder.transform([['blue']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971c0f88",
   "metadata": {},
   "source": [
    "## Ordinal Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e4afb6",
   "metadata": {},
   "source": [
    "Ordinal Encoding assigns integer values to categories based on their order or ranking.\n",
    "\n",
    "Unlike label encoding (which is arbitrary), ordinal encoding assumes the categories follow a logical order.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba901939",
   "metadata": {},
   "source": [
    " [\"Small\", \"Large\", \"Medium\", \"Small\"] ‚Üí [0, 2, 1, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a39f39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "df=pd.DataFrame({'size':['small','medium','large','medium','small','large']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6af93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53545a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "## instance of ordinal encoder and then fit_transform\n",
    "encoder=OrdinalEncoder(categories=[['small','medium','large']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789753bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.fit_transform(df[['size']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded67e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.transform([['small']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8238cf9",
   "metadata": {},
   "source": [
    "## Target Guided Ordinal Encoding\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d682d8fa",
   "metadata": {},
   "source": [
    "Target Guided Ordinal Encoding is a categorical encoding technique in which:\n",
    "\n",
    "Categories are replaced with ordinal numbers based on the average (or other statistic) of the target variable for each category.\n",
    "\n",
    "This method uses the relationship between the categorical feature and the target variable to assign meaningful numerical values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40da22d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame({\n",
    "    'city':['newyork','london','paris','tokyo','newyork','paris'],\n",
    "    'price':[200,150,300,250,180,320]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa00b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dcc8d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_price=df.groupby('city')['price'].mean().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10224bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc3639f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['city_encoded']=df['city'].map(mean_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede0448e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208899f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['city','city_encoded']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
